{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\human\\AppData\\Local\\Temp\\ipykernel_2936\\820811571.py:11: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, 'html.parser').get_text()\n",
      "C:\\Users\\human\\AppData\\Local\\Temp\\ipykernel_2936\\820811571.py:11: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  text = BeautifulSoup(text, 'html.parser').get_text()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # HTML 태그 제거\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "\n",
    "    # 정규표현식을 사용하여 한글만 남기고 나머지는 제거\n",
    "    text = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\", text)\n",
    "\n",
    "    # 형태소 분석\n",
    "    tokens = okt.morphs(text, stem=True)\n",
    "\n",
    "    # 불용어 제거\n",
    "    with open('data/한글불용어100.txt') as st:\n",
    "        lines = st.readlines()\n",
    "    \n",
    "    stop_words = []\n",
    "    for line in lines:\n",
    "        word = line.split('\\t')[0]\n",
    "        stop_words.append(word)\n",
    "        stop_words = [line.split('\\t')[0] for line in lines]\n",
    "    \n",
    "    \n",
    "    # 형태소 분석기를 돌려서 나온 결과에서 불용어 제거하기\n",
    "    morphs = okt.morphs(text, stem=True)\n",
    "    clean_morphs = [morph for morph in morphs if morph not in stop_words]\n",
    "    clean_morphs\n",
    "    \n",
    "    # Feature 변환을 위한 Vectorizer의 입력은 리스트가 아닌 문자열이어야 함\n",
    "    clean_text = ' '.join(clean_morphs)\n",
    "    \n",
    "    # 정제된 텍스트 반환\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def process_qa_csv(input_file, output_file):\n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(input_file, encoding='utf-8')\n",
    "\n",
    "    # '질문'과 '답변' 열에 대해 정제 함수 적용\n",
    "    df['정제된_질문'] = df['질문'].apply(preprocess_text)\n",
    "    df['정제된_답변'] = df['답변'].apply(preprocess_text)\n",
    "\n",
    "    # 질문과 답변을 쌍으로 가지는 형태로 바꾸기\n",
    "    chatbot_data = [{'질문': q, '답변': a} for q, a in zip(df['정제된_질문'], df['정제된_답변'])]\n",
    "\n",
    "    # 데이터프레임으로 변환\n",
    "    chatbot_df = pd.DataFrame(chatbot_data)\n",
    "\n",
    "    # 정제된 데이터를 CSV 파일로 저장\n",
    "    chatbot_df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "\n",
    "# 사용 예시\n",
    "process_qa_csv('data/세훈재훈민준_결측수정.csv', 'data/chatbot_data3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부동산 이 나오다 각각 계약 에 다 집주인 이 다른 상황 이다 첫 계약 을 월일 에 하게 매월 일 에 월세 가 지급 되다 조건 으로 월세 계약서 를 작성 하게 임대 인 에게 말씀 하게 협의 가 필요하게 사항 이다\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Komoran\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "def load_data(csv_path):\n",
    "    df = pd.read_csv(csv_path, encoding='utf-8')\n",
    "    return df\n",
    "\n",
    "# 텍스트 전처리 함수\n",
    "def preprocess_text(text, tokenizer):\n",
    "    tokens = tokenizer.morphs(text)  # 형태소 분석\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# 챗봇 함수 구현\n",
    "def create_chatbot(csv_path, tokenizer):\n",
    "    # 데이터 불러오기\n",
    "    df = load_data(csv_path)\n",
    "\n",
    "    # 텍스트 전처리\n",
    "    df['processed_question'] = df['질문'].apply(lambda x: preprocess_text(x, tokenizer))\n",
    "\n",
    "    # TF-IDF 벡터화\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(df['processed_question'])\n",
    "\n",
    "    # 챗봇 함수\n",
    "    def chatbot(user_input):\n",
    "        # 사용자 입력 전처리\n",
    "        processed_input = preprocess_text(user_input, tokenizer)\n",
    "\n",
    "        # 사용자 입력을 TF-IDF로 변환\n",
    "        input_vector = vectorizer.transform([processed_input])\n",
    "\n",
    "        # 코사인 유사도 계산\n",
    "        similarities = cosine_similarity(input_vector, tfidf_matrix).flatten()\n",
    "\n",
    "        # 가장 유사한 질문의 인덱스 찾기\n",
    "        max_similarity_index = similarities.argmax()\n",
    "\n",
    "        # 해당 인덱스에 대응하는 답변 출력\n",
    "        response = df.loc[max_similarity_index, '답변']\n",
    "        return response\n",
    "\n",
    "    return chatbot\n",
    "\n",
    "# 챗봇 생성\n",
    "csv_path = 'data/chatbot_data3.csv'\n",
    "tokenizer = Okt()  # 형태소 분석기에 맞게 수정\n",
    "chatbot = create_chatbot(csv_path, tokenizer)\n",
    "\n",
    "# 테스트\n",
    "user_input = \"월세 계약시 알아야 할점을 알려주세요.\"\n",
    "response = chatbot(user_input)\n",
    "if '하다 하다' in response:\n",
    "    text = response.replace('하다 하다','해야 합니다.')\n",
    "elif '하다' in response:\n",
    "    text = response.replace('하다', '하게')\n",
    "elif '이다' in response:\n",
    "    text = response.replace('이다', '입니다.')\n",
    "else:\n",
    "    pass\n",
    "\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
